FROM repo.despera.space/iru/rocm:5.4.3-torch5.4.2
ENV CC=/opt/rocm/llvm/bin/clang
ENV CXX=/opt/rocm/llvm/bin/clang++
EXPOSE 5001
RUN git clone https://github.com/YellowRoseCx/koboldcpp-rocm -b main --depth 1 /app
WORKDIR /app
RUN make LLAMA_HIPBLAS=1 -j
CMD [ "/app/koboldcpp.py", "--smartcontext", "--gpulayers", "33", "--usecublas", "0", "--model", "/model.bin" ]
